{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week5 Assignments - Plotting\n",
    "\n",
    "This assignment is exploratory. You still have to submit the assignment, but no need to follow the specific instructions provided.\n",
    "\n",
    "The basic idea is to play with some of the plotting functions. Plotting tends to be somewhat situation- and data- specific. If you already have data, we encourage you to use those data in this assignment and play around with some plots. We can provide feedback through OKPy to any explicit questions you may have or anything we notice in your code.\n",
    "\n",
    "If you do not have data, you can obtain data from any of the following sources:\n",
    "* https://catalog.data.gov/dataset\n",
    "* http://mlr.cs.umass.edu/ml/datasets.html\n",
    "* https://www.kaggle.com/datasets\n",
    "* https://opendata.socrata.com\n",
    "\n",
    "\n",
    "\n",
    "Either from your data or from the data provided above, try to create plots to glean anything interesting from the data. Plot features against each other and color by some factor, overlay histograms of different features, create boxplots, etc. Feel free to look at some of the plot templates available on the matplotlib / bokeh / seaborn websites, and see if you can recreate something they have done.\n",
    "\n",
    "For more specificity, you can try to work through the following tasks:\n",
    "1. With matplotlib: Plot a notched boxplot of a given feature.\n",
    "2. With matplotlib: Plot an overlaid histogram of two features, each feature in a different color.\n",
    "3. With Pandas: Plot a histogram of a specific column.\n",
    "4. With Seaborn: Plot a histogram with a density line.\n",
    "5. With Seaborn: Plot a scatterplot with a trend line.\n",
    "6. With matplotlib: Plot three scatterplots on the same plot, with each having a different color and shape.\n",
    "\n",
    "Do not necessarily feel bound by these tasks - while you should know how to complete them, preferably look at your dataset and think of plots that would be informative, and try to implement them. \n",
    "\n",
    "If you don't have a dataset that catches your interest, you can use sklearn's built-in wine dataset. In the cell below we've provided the code to load it and format it for easier use. We've also provided the solution to the first task using the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# This is part of the exploratory data analysis step of my project in which I \n",
    "# determine the optimal parameters for running a ChIP-Seq peak-caller. \n",
    "\n",
    "# This file creates binary heatmaps of optimal parameter combinations\n",
    "# for running MACS2, a ChIP-Seq peak-caller. ChIP-Seq peak-callers identify\n",
    "# locations of protein-binding in DNA. MACS2 is an alogrithm for doing that.\n",
    "# The optimal parameter combination was defined as the combination\n",
    "# which maximizes the Matthews Correlation Coefficient of the data. \n",
    "\n",
    "# The input files are f_ca and f_sample, which have the optimal peak-caller combinations for \n",
    "# each celltype-antibody combiation and for each sample, respectively.\n",
    "# The other files are all of the output files that use different \n",
    "\n",
    "f_ca = \"/data/Lei_student/Hussain/ML/dm6/peakerror/optimal/optimal_ca.csv\"\n",
    "f_sample = \"/data/Lei_student/Hussain/ML/dm6/peakerror/optimal/optimal_sample.csv\"\n",
    "o_ca = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_heatmap_ca.png\"\n",
    "o_ca_clust = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_average_ca.png\"\n",
    "o_sample = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_heatmap_sample.png\"\n",
    "o_sample_clust = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_average_sample.png\"\n",
    "o_ca_sum = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_heatmap_ca_sum_sorted.png\"\n",
    "o_sample_sum = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_heatmap_sample_sum_sorted.png\"\n",
    "o_ca_clust_complete = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_complete_ca.png\"\n",
    "o_sample_clust_complete = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_complete_sample.png\"\n",
    "o_ca_clust_single = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_single_ca.png\"\n",
    "o_sample_clust_single = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_single_sample.png\"\n",
    "o_ca_clust_ward = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_ward_ca.png\"\n",
    "o_sample_clust_ward = \"/data/Lei_student/Hussain/ML/dm6/peakerror/binary_heatmap/binary_clustermap_ward_sample.png\"\n",
    "\n",
    "# These lines read in the input and convert them to DataFrames.\n",
    "df_ca = pd.DataFrame.from_csv(f_ca)\n",
    "df_sample = pd.DataFrame.from_csv(f_sample)\n",
    "\n",
    "# These are the MACS2 peak-caller parameter combinations. \n",
    "q_value = [.03, .04, .05, .06, .07]\n",
    "slocal = [500, 1000, 1500]\n",
    "llocal = [5000, 10000, 15000]\n",
    "highmfold = [30, 40, 50, 60, 70]\n",
    "lowmfold = [3, 4, 5, 6, 7]\n",
    "\n",
    "x_ca = [] # List of dictionaries with binary heatmap values for each celltype-antibody combination. This will be converted to a DataFrame.\n",
    "x_sample = [] # The list of dictionaries for each sample.\n",
    "\n",
    "x_ca_labels = []\n",
    "\n",
    "for index, row in df_ca.iterrows(): \n",
    "    \"\"\"\n",
    "    Iterate through each optimal celltype-antibody combination value and add a 1.0 for the optimal parameter and leave all other parameters empty.\n",
    "    \"\"\"\n",
    "    temp_dict = {}\n",
    "    temp_dict[\"ca\"] = row[\"celltype\"] + \"_\" + row[\"antibody\"]\n",
    "    temp_dict[\"q_value_\" + str(row[\"q_value\"])] = 1.0\n",
    "    temp_dict[\"slocal_\" + str(row[\"slocal\"])] = 1.0\n",
    "    temp_dict[\"llocal_\" + str(row[\"llocal\"])] = 1.0\n",
    "    temp_dict[\"highmfold_\" + str(row[\"highmfold\"])] = 1.0\n",
    "    temp_dict[\"lowmfold_\" + str(row[\"lowmfold\"])] = 1.0\n",
    "    x_ca.append(temp_dict)\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    \"\"\"\n",
    "    Iterate through each optimal sample combination value and add a 1.0 for the optimal parameter and leave all other parameters empty.\n",
    "    \"\"\"\n",
    "    temp_dict = {}\n",
    "    temp_dict[\"samples\"] = row[\"sample\"]\n",
    "    temp_dict[\"q_value_\" + str(row[\"q_value\"])] = 1.0\n",
    "    temp_dict[\"slocal_\" + str(row[\"slocal\"])] = 1.0\n",
    "    temp_dict[\"llocal_\" + str(row[\"llocal\"])] = 1.0\n",
    "    temp_dict[\"highmfold_\" + str(row[\"highmfold\"])] = 1.0\n",
    "    temp_dict[\"lowmfold_\" + str(row[\"lowmfold\"])] = 1.0\n",
    "    x_sample.append(temp_dict)\n",
    "\n",
    "x_ca_df = pd.DataFrame(x_ca) # Convert the lists to DataFrames and add zero values\n",
    "x_sample_df = pd.DataFrame(x_sample)\n",
    "\n",
    "x_ca_df.index = x_ca_df[\"ca\"] # Index the DataFrames by their labels\n",
    "x_sample_df.index = x_sample_df[\"samples\"]\n",
    "\n",
    "x_ca_df = x_ca_df.sort_values(x_ca_df.columns.tolist()).fillna(0.0) # Sort them by columns and relpace Na with zero\n",
    "x_sample_df = x_sample_df.sort_values(x_sample_df.columns.tolist()).fillna(0.0)\n",
    "\n",
    "x_ca_df2 = x_ca_df.drop([\"ca\"], axis=1) # Remove the first axis \n",
    "x_sample_df2 = x_sample_df.drop([\"samples\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The follow codes creates heatmaps and clustermaps of the dataframes but use the sum of each parameter combination to sort the columns\n",
    "\n",
    "# Several of the clustermaps differ in the methods they use for clustering.\n",
    "# In this code, I'm using \"average\", \"complete\", \"single\", and \"ward.\" \n",
    "# The mathematics behind each clustering method is found here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "# Hamming distance is used for the metric as that corresponds to binary distances.\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Heatmap of optimal values for each celltype-antibody combination\n",
    "ax = sns.heatmap(x_ca_df2, cmap=plt.cm.binary, xticklabels=True)\n",
    "ax.set_yticklabels(x_ca_df.ca.values, rotation=0)\n",
    "plt.savefig(o_ca)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Heatmap of optimal values for each sample\n",
    "ax = sns.heatmap(x_sample_df2, cmap=plt.cm.binary, xticklabels=True)\n",
    "ax.set_yticklabels(x_sample_df.samples.values, rotation=0)\n",
    "plt.savefig(o_sample)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of optimal values for each celltype-antibody combination using the \"average\" method.\n",
    "ax = sns.clustermap(x_ca_df2, metric=\"hamming\", method=\"average\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_ca_clust)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of optimal values for each sample using the \"average\" method.\n",
    "ax = sns.clustermap(x_sample_df2, metric=\"hamming\", method=\"average\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_sample_clust)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of each celltype-antibody combination using the \"complete\" method.\n",
    "ax = sns.clustermap(x_ca_df2, metric=\"hamming\", method=\"complete\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_ca_clust_complete)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of each sample using the \"complete\" method.\n",
    "ax = sns.clustermap(x_sample_df2, metric=\"hamming\", method=\"complete\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_sample_clust_complete)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of each celltype-antibody combination using the \"single\" method.\n",
    "ax = sns.clustermap(x_ca_df2, metric=\"hamming\", method=\"single\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_ca_clust_single)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of each sample using the \"single\" method.\n",
    "ax = sns.clustermap(x_sample_df2, metric=\"hamming\", method=\"single\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_sample_clust_single)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of each cell-type antibody combination using the \"Ward\" method.\n",
    "ax = sns.clustermap(x_ca_df2, metric=\"euclidean\", method=\"ward\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_ca_clust_ward)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) # Clustermap of each sample using the \"Ward\" method. \n",
    "ax = sns.clustermap(x_sample_df2, metric=\"euclidean\", method=\"ward\", cmap=plt.cm.binary, xticklabels=True)\n",
    "plt.setp(ax.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.savefig(o_sample_clust_ward)\n",
    "\n",
    "x_ca_df2_indices = x_ca_df2.sum().sort_values().index.tolist() # Sort the indices by sum\n",
    "x_sample_df2_indices = x_sample_df2.sum().sort_values().index.tolist()\n",
    "\n",
    "fig = plt.figure(figsize = (14,10)) \n",
    "ax = sns.heatmap(x_ca_df2[x_ca_df2_indices], cmap=plt.cm.binary, xticklabels=True)\n",
    "ax.set_yticklabels(x_ca_df.ca.values, rotation=0)\n",
    "plt.savefig(o_ca_sum)\n",
    "\n",
    "fig = plt.figure(figsize = (14,10))\n",
    "ax = sns.heatmap(x_sample_df2[x_sample_df2_indices], cmap=plt.cm.binary, xticklabels=True)\n",
    "ax.set_yticklabels(x_sample_df.samples.values, rotation=0)\n",
    "plt.savefig(o_sample_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
